{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea57d240",
   "metadata": {},
   "source": [
    "# Some assumptions to make before analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10785dc3",
   "metadata": {},
   "source": [
    "1. We only include the employees working in North America in our dataset.\n",
    "2. We focus on the general industry, such as Entertainment, Finance, Retial, Manufacturing, Fashion and IT, etc.\n",
    "3. We define gender as 4 types (Female, Male, Non-binary and Trans).\n",
    "4. The total salary is comprised of the annual base salary and anuual bonus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d535cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\\\U of A\\\\job searching\\\\documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b46b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_excel('Anonymous Salary Survey.xlsx')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd713e72",
   "metadata": {},
   "source": [
    "Adding a file: North American states and provinces.\n",
    "Mapping each state code to the corresponding state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1ea9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('North American states and provinces.txt', 'r') as file_:\n",
    "    data = file_.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23f0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2346d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)//6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22902e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = pd.DataFrame(data = np.zeros((102,3)), columns = ['Code','State','Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1466ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file2['Code'])):\n",
    "    file2.loc[i,'Code'] = data[6*i + 1]\n",
    "    file2.loc[i,'State'] = data[6*i + 3]\n",
    "    file2.loc[i,'Country'] = data[6*i + 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7050c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "file2['code_state'] = file2['Code'] + ' ' + file2['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c164f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>code_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>US</td>\n",
       "      <td>AK Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>AL Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>US</td>\n",
       "      <td>AZ Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>US</td>\n",
       "      <td>AR Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>CA California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TAM</td>\n",
       "      <td>Tamaulipas</td>\n",
       "      <td>MX</td>\n",
       "      <td>TAM Tamaulipas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>TLA</td>\n",
       "      <td>Tlaxcala</td>\n",
       "      <td>MX</td>\n",
       "      <td>TLA Tlaxcala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VER</td>\n",
       "      <td>Veracruz Llave</td>\n",
       "      <td>MX</td>\n",
       "      <td>VER Veracruz Llave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>YUC</td>\n",
       "      <td>Yucatan</td>\n",
       "      <td>MX</td>\n",
       "      <td>YUC Yucatan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ZAC</td>\n",
       "      <td>Zacatecas</td>\n",
       "      <td>MX</td>\n",
       "      <td>ZAC Zacatecas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code           State Country          code_state\n",
       "0     AK          Alaska      US           AK Alaska\n",
       "1     AL         Alabama      US          AL Alabama\n",
       "2     AZ         Arizona      US          AZ Arizona\n",
       "3     AR        Arkansas      US         AR Arkansas\n",
       "4     CA      California      US       CA California\n",
       "..   ...             ...     ...                 ...\n",
       "97   TAM      Tamaulipas      MX      TAM Tamaulipas\n",
       "98   TLA        Tlaxcala      MX        TLA Tlaxcala\n",
       "99   VER  Veracruz Llave      MX  VER Veracruz Llave\n",
       "100  YUC         Yucatan      MX         YUC Yucatan\n",
       "101  ZAC       Zacatecas      MX       ZAC Zacatecas\n",
       "\n",
       "[102 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cfa5f",
   "metadata": {},
   "source": [
    "Adding a file: America major cities and states.\n",
    "Mapping each American city to the corresponding state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bcc0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('America major cities and states.txt', 'r') as file__:\n",
    "    data2 = file__.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ab4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.split('\\n')\n",
    "data3 = []\n",
    "for i in range(len(data2)):\n",
    "    list = data2[i].split('\\t')\n",
    "    for l in list:\n",
    "        data3.append(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ead7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data3)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b859265",
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = pd.DataFrame(data = np.zeros((50,3)), columns = ['State','capital','major_city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea107cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(file3['State'])):\n",
    "    file3.loc[i,'State'] = data3[3*i]\n",
    "    file3.loc[i,'capital'] = data3[3*i + 1]\n",
    "    file3.loc[i,'major_city'] = data3[3*i + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8368e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>capital</th>\n",
       "      <th>major_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Birmingham, Montgomery, Mobile, Huntsville, Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>Anchorage, Fairbanks, Juneau, Sitka, Ketchikan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Phoenix, Tucson, Mesa, Chandler, Glendale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>Little Rock, Fort Smith, North Little Rock, Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Sacramento</td>\n",
       "      <td>Los Angeles, San Diego, San Jose, San Francisc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Denver, Colorado Springs, Aurora, Fort Collins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Hartford</td>\n",
       "      <td>Bridgeport, New Haven, Hartford, Stamford, Wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Dover</td>\n",
       "      <td>Wilmington, Dover, Newark, Middletown, Smyrna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>Jacksonville, Miami, Tampa, St. Petersburg, Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Atlanta, Augusta-Richmond, Columbus, Savannah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>Honolulu, Hilo1, Kailua1, Kapolei1, Kaneohe1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>Boise</td>\n",
       "      <td>Boise, Nampa, Meridian, Idaho Falls, Pocatello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Chicago, Aurora, Rockford, Joliet, Naperville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indianapolis, Fort Wayne, Evansville, South Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Des Moines</td>\n",
       "      <td>Des Moines, Cedar Rapids, Davenport, Sioux Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>Topeka</td>\n",
       "      <td>Wichita, Overland Park, Kansas City, Topeka, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Frankfort</td>\n",
       "      <td>Louisville, Lexington, Bowling Green, Owensbor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>New Orleans, Baton Rouge, Shreveport, Lafayett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>Augusta</td>\n",
       "      <td>Portland, Lewiston, Bangor, South Portland, Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>Baltimore, Frederick, Rockville, Gaithersburg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Boston, Worcester, Springfield, Lowell, Cambridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lansing</td>\n",
       "      <td>Detroit, Grand Rapids, Warren, Sterling Height...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Saint Paul</td>\n",
       "      <td>Minneapolis, Saint Paul, Rochester, Duluth, Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Jackson, Gulfport, Hattiesburg, Southaven, Biloxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>Jefferson City</td>\n",
       "      <td>Kansas City, Saint Louis, Springfield, Indepen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>Helena</td>\n",
       "      <td>Billings, Missoula, Great Falls, Bozeman, Butte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>Omaha, Lincoln, Bellevue, Grand Island, Kearney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>Carson City</td>\n",
       "      <td>Las Vegas, Henderson, North Las Vegas, Reno, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Concord</td>\n",
       "      <td>Manchester, Nashua, Concord, Derry, Rochester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Trenton</td>\n",
       "      <td>Newark, Jersey City, Paterson, Elizabeth, Edison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Santa Fe</td>\n",
       "      <td>Albuquerque, Las Cruces, Rio Rancho, Santa Fe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>Albany</td>\n",
       "      <td>New York, Buffalo, Rochester, Yonkers, Syracuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>Charlotte, Raleigh, Greensboro, Winston-Salem,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>Bismarck</td>\n",
       "      <td>Fargo, Bismarck, Grand Forks, Minot, West Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>Columbus, Cleveland, Cincinnati, Toledo, Akron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>Oklahoma City, Tulsa, Norman, Broken Arrow, La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>Salem</td>\n",
       "      <td>Portland, Eugene, Salem, Gresham, Hillsboro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>Philadelphia, Pittsburgh, Allentown, Erie, Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>Providence</td>\n",
       "      <td>Providence, Warwick, Cranston, Pawtucket, East...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>Columbia, Charleston, North Charleston, Mount ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>Pierre</td>\n",
       "      <td>Sioux Falls, Rapid City, Aberdeen, Brookings, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>Memphis, Nashville, Knoxville, Chattanooga, Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Houston, San Antonio, Dallas, Austin, Fort Worth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Salt Lake City, West Valley City, Provo, West ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>Montpelier</td>\n",
       "      <td>Burlington, Essex, South Burlington, Colcheste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Virginia Beach, Norfolk, Chesapeake, Richmond,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>Seattle, Spokane, Tacoma, Vancouver, Bellevue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>Charleston, Huntington, Parkersburg, Morgantow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Milwaukee, Madison, Green Bay, Kenosha, Racine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>Cheyenne, Casper, Laramie, Gillette, Rock Springs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State         capital  \\\n",
       "0          Alabama      Montgomery   \n",
       "1           Alaska          Juneau   \n",
       "2          Arizona         Phoenix   \n",
       "3         Arkansas     Little Rock   \n",
       "4       California      Sacramento   \n",
       "5         Colorado          Denver   \n",
       "6      Connecticut        Hartford   \n",
       "7         Delaware           Dover   \n",
       "8          Florida     Tallahassee   \n",
       "9          Georgia         Atlanta   \n",
       "10          Hawaii        Honolulu   \n",
       "11           Idaho           Boise   \n",
       "12        Illinois     Springfield   \n",
       "13         Indiana    Indianapolis   \n",
       "14            Iowa      Des Moines   \n",
       "15          Kansas          Topeka   \n",
       "16        Kentucky       Frankfort   \n",
       "17       Louisiana     Baton Rouge   \n",
       "18           Maine         Augusta   \n",
       "19        Maryland       Annapolis   \n",
       "20   Massachusetts          Boston   \n",
       "21        Michigan         Lansing   \n",
       "22       Minnesota      Saint Paul   \n",
       "23     Mississippi         Jackson   \n",
       "24        Missouri  Jefferson City   \n",
       "25         Montana          Helena   \n",
       "26        Nebraska         Lincoln   \n",
       "27          Nevada     Carson City   \n",
       "28   New Hampshire         Concord   \n",
       "29      New Jersey         Trenton   \n",
       "30      New Mexico        Santa Fe   \n",
       "31        New York          Albany   \n",
       "32  North Carolina         Raleigh   \n",
       "33    North Dakota        Bismarck   \n",
       "34            Ohio        Columbus   \n",
       "35        Oklahoma   Oklahoma City   \n",
       "36          Oregon           Salem   \n",
       "37    Pennsylvania      Harrisburg   \n",
       "38    Rhode Island      Providence   \n",
       "39  South Carolina        Columbia   \n",
       "40    South Dakota          Pierre   \n",
       "41       Tennessee       Nashville   \n",
       "42           Texas          Austin   \n",
       "43            Utah  Salt Lake City   \n",
       "44         Vermont      Montpelier   \n",
       "45        Virginia        Richmond   \n",
       "46      Washington         Olympia   \n",
       "47   West Virginia      Charleston   \n",
       "48       Wisconsin         Madison   \n",
       "49         Wyoming        Cheyenne   \n",
       "\n",
       "                                           major_city  \n",
       "0   Birmingham, Montgomery, Mobile, Huntsville, Tu...  \n",
       "1      Anchorage, Fairbanks, Juneau, Sitka, Ketchikan  \n",
       "2           Phoenix, Tucson, Mesa, Chandler, Glendale  \n",
       "3   Little Rock, Fort Smith, North Little Rock, Fa...  \n",
       "4   Los Angeles, San Diego, San Jose, San Francisc...  \n",
       "5   Denver, Colorado Springs, Aurora, Fort Collins...  \n",
       "6   Bridgeport, New Haven, Hartford, Stamford, Wat...  \n",
       "7       Wilmington, Dover, Newark, Middletown, Smyrna  \n",
       "8   Jacksonville, Miami, Tampa, St. Petersburg, Or...  \n",
       "9   Atlanta, Augusta-Richmond, Columbus, Savannah,...  \n",
       "10       Honolulu, Hilo1, Kailua1, Kapolei1, Kaneohe1  \n",
       "11     Boise, Nampa, Meridian, Idaho Falls, Pocatello  \n",
       "12      Chicago, Aurora, Rockford, Joliet, Naperville  \n",
       "13  Indianapolis, Fort Wayne, Evansville, South Be...  \n",
       "14  Des Moines, Cedar Rapids, Davenport, Sioux Cit...  \n",
       "15  Wichita, Overland Park, Kansas City, Topeka, O...  \n",
       "16  Louisville, Lexington, Bowling Green, Owensbor...  \n",
       "17  New Orleans, Baton Rouge, Shreveport, Lafayett...  \n",
       "18  Portland, Lewiston, Bangor, South Portland, Au...  \n",
       "19  Baltimore, Frederick, Rockville, Gaithersburg,...  \n",
       "20  Boston, Worcester, Springfield, Lowell, Cambridge  \n",
       "21  Detroit, Grand Rapids, Warren, Sterling Height...  \n",
       "22  Minneapolis, Saint Paul, Rochester, Duluth, Bl...  \n",
       "23  Jackson, Gulfport, Hattiesburg, Southaven, Biloxi  \n",
       "24  Kansas City, Saint Louis, Springfield, Indepen...  \n",
       "25    Billings, Missoula, Great Falls, Bozeman, Butte  \n",
       "26    Omaha, Lincoln, Bellevue, Grand Island, Kearney  \n",
       "27  Las Vegas, Henderson, North Las Vegas, Reno, S...  \n",
       "28      Manchester, Nashua, Concord, Derry, Rochester  \n",
       "29   Newark, Jersey City, Paterson, Elizabeth, Edison  \n",
       "30  Albuquerque, Las Cruces, Rio Rancho, Santa Fe,...  \n",
       "31    New York, Buffalo, Rochester, Yonkers, Syracuse  \n",
       "32  Charlotte, Raleigh, Greensboro, Winston-Salem,...  \n",
       "33    Fargo, Bismarck, Grand Forks, Minot, West Fargo  \n",
       "34     Columbus, Cleveland, Cincinnati, Toledo, Akron  \n",
       "35  Oklahoma City, Tulsa, Norman, Broken Arrow, La...  \n",
       "36        Portland, Eugene, Salem, Gresham, Hillsboro  \n",
       "37  Philadelphia, Pittsburgh, Allentown, Erie, Rea...  \n",
       "38  Providence, Warwick, Cranston, Pawtucket, East...  \n",
       "39  Columbia, Charleston, North Charleston, Mount ...  \n",
       "40  Sioux Falls, Rapid City, Aberdeen, Brookings, ...  \n",
       "41  Memphis, Nashville, Knoxville, Chattanooga, Cl...  \n",
       "42   Houston, San Antonio, Dallas, Austin, Fort Worth  \n",
       "43  Salt Lake City, West Valley City, Provo, West ...  \n",
       "44  Burlington, Essex, South Burlington, Colcheste...  \n",
       "45  Virginia Beach, Norfolk, Chesapeake, Richmond,...  \n",
       "46      Seattle, Spokane, Tacoma, Vancouver, Bellevue  \n",
       "47  Charleston, Huntington, Parkersburg, Morgantow...  \n",
       "48     Milwaukee, Madison, Green Bay, Kenosha, Racine  \n",
       "49  Cheyenne, Casper, Laramie, Gillette, Rock Springs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f82cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Age Range', 'Years of Experience', 'Industry',\n",
       "       'Industry_edited', 'Job Title', 'Company Name',\n",
       "       'Highest Level of Education Received',\n",
       "       'Closest Major City and State (e.g. Santa Clara, CA)', 'Country',\n",
       "       'Annual Base Salary (if hourly, please convert to annual)',\n",
       "       'Annual Bonus', 'Annual Average of RSUs',\n",
       "       'Signing Bonus (if none, leave blank)', 'Currency (USD, CAD, etc)',\n",
       "       'How many vacation days are you given per year?',\n",
       "       'How many sick days are you given per year?',\n",
       "       'How many days per week are you required to work onsite/in the office?',\n",
       "       'Do you openly discuss salary with your colleagues?',\n",
       "       'How many months Maternity or Paternity does your company offer?',\n",
       "       'Gender (optional)', 'Unnamed: 21', 'Diverse Identity (Optional)',\n",
       "       'Unnamed: 23', ' ', ' .1', ' .2', ' .3', ' .4', ' .5', ' .6', ' .7',\n",
       "       ' .8', ' .9', ' .10', ' .11', ' .12', ' .13', ' .14', ' .15', ' .16',\n",
       "       ' .17', ' .18', ' .19', ' .20', ' .21', ' .22', ' .23', ' .24', ' .25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e211b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file.drop(['Unnamed: 21','Unnamed: 23',' ', ' .1', ' .2', ' .3', ' .4', ' .5', ' .6', ' .7',' .8', ' .9', ' .10', ' .11', ' .12', ' .13', ' .14', ' .15', ' .16',' .17', ' .18', ' .19', ' .20', ' .21', ' .22', ' .23', ' .24', ' .25'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4388202",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file.drop(['Company Name','Annual Average of RSUs','Signing Bonus (if none, leave blank)','How many days per week are you required to work onsite/in the office?','Do you openly discuss salary with your colleagues?','Diverse Identity (Optional)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48c527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Bachelor's Degree\", 'Some College credit, no degree',\n",
       "       'High School Graduate, Diploma or the equivalent (e.g. GED)',\n",
       "       \"Master's Degree\", 'Associate Degree', 'No Schooling Completed',\n",
       "       'Doctorate Degree', 'Trade, Technical, Vocational Training', nan,\n",
       "       'Professional Degree', 'Some High School, No Diploma'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Highest Level of Education Received'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57de822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file[file['Highest Level of Education Received']=='High School Graduate, Diploma or the equivalent (e.g. GED)']='High School'\n",
    "file[file['Highest Level of Education Received']=='Some High School, No Diploma']='High School'\n",
    "file[file['Highest Level of Education Received']=='Trade, Technical, Vocational Training']='Professional Degree'\n",
    "file[file['Highest Level of Education Received']=='Some College credit, no degree']='No Degree'\n",
    "file[file['Highest Level of Education Received']=='No Schooling Completed']='No Degree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44ac3678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Bachelor's Degree\", 'No Degree', 'High School', \"Master's Degree\",\n",
       "       'Associate Degree', 'Doctorate Degree', 'Professional Degree', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Highest Level of Education Received'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb858703",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(subset = ['Currency (USD, CAD, etc)','Years of Experience','Industry','Highest Level of Education Received','Closest Major City and State (e.g. Santa Clara, CA)','Gender (optional)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f6e5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df23a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file.rename(columns={\"Highest Level of Education Received\": \"Level of Education\", \"Closest Major City and State (e.g. Santa Clara, CA)\": \"Major City\",\"Annual Base Salary (if hourly, please convert to annual)\":\"Annual Salary\",\"Currency (USD, CAD, etc)\":\"Currency\",\"How many vacation days are you given per year?\":\"Vacation per Year\",\"How many sick days are you given per year?\":\"Sick Days per Year\",\"How many months Maternity or Paternity does your company offer?\":\"Maternity/Paternity per Year\",\"Gender (optional)\":\"Gender\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e278ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54082 entries, 0 to 54081\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Timestamp                     54082 non-null  object\n",
      " 1   Age Range                     54063 non-null  object\n",
      " 2   Years of Experience           54082 non-null  object\n",
      " 3   Industry                      54082 non-null  object\n",
      " 4   Industry_edited               42546 non-null  object\n",
      " 5   Job Title                     53648 non-null  object\n",
      " 6   Level of Education            54082 non-null  object\n",
      " 7   Major City                    54082 non-null  object\n",
      " 8   Country                       52762 non-null  object\n",
      " 9   Annual Salary                 54017 non-null  object\n",
      " 10  Annual Bonus                  39567 non-null  object\n",
      " 11  Currency                      54082 non-null  object\n",
      " 12  Vacation per Year             50939 non-null  object\n",
      " 13  Sick Days per Year            45054 non-null  object\n",
      " 14  Maternity/Paternity per Year  35182 non-null  object\n",
      " 15  Gender                        54082 non-null  object\n",
      "dtypes: object(16)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c1240f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54082, 16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b92a441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'Age Range', 'Years of Experience', 'Industry',\n",
       "       'Industry_edited', 'Job Title', 'Level of Education', 'Major City',\n",
       "       'Country', 'Annual Salary', 'Annual Bonus', 'Currency',\n",
       "       'Vacation per Year', 'Sick Days per Year',\n",
       "       'Maternity/Paternity per Year', 'Gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d24d5",
   "metadata": {},
   "source": [
    "# Extract state/province from major city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0acec6",
   "metadata": {},
   "source": [
    "Spliting the cities and states from raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4f03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['State/Province']=np.zeros((file.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "502802c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cities in enumerate(file['Major City']):\n",
    "    file.loc[i,'Major City'] = cities.split(',')[0]\n",
    "    file.loc[i,'State/Province'] = cities.split(',')[1] if len(cities.split(',')) == 2 else np.nan\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ed44a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, states in enumerate(file['State/Province']):\n",
    "    file.loc[i,'State/Province'] = ''.join([state.upper() for state in str(states) if state.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83eb2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, states in enumerate(file['State/Province']):\n",
    "    for k, j in enumerate(file2['code_state']):\n",
    "        if (j.split(' ')[0]).upper() in states:\n",
    "            file.loc[i, 'State/Province'] = file2.loc[k, 'State']\n",
    "        elif (j.split(' ')[1]).upper() in states:\n",
    "            file.loc[i, 'State/Province'] = file2.loc[k, 'State']\n",
    "        else:\n",
    "            file.loc[i, 'State/Province'] = file.loc[i, 'State/Province']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "706aa62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cities in enumerate(file['Major City']):\n",
    "    for k, j in enumerate(file3['major_city']):\n",
    "        if cities.lower() in j.lower():\n",
    "            file.loc[i, 'State/Province'] = file3.loc[k, 'State']\n",
    "        elif (j.split(' ')[1]).upper() in states:\n",
    "            file.loc[i, 'State/Province'] = file3.loc[k, 'State']\n",
    "        else:\n",
    "            file.loc[i, 'State/Province'] = file.loc[i, 'State/Province']\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bdae7fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pennsylvania', 'NAN', 'Texas', 'Minnesota', 'Illinois',\n",
       "       'Wisconsin', 'Florida', 'Rhode Island', 'Utah', 'New York',\n",
       "       'Ontario', 'Massachusetts', 'California', 'Delaware', 'New Mexico',\n",
       "       'Alberta', 'North Carolina', 'Washington', 'Missouri',\n",
       "       'West Virginia', 'District of Columbia', 'Nebraska', 'Colorado',\n",
       "       'Georgia', 'Ohio', 'New Brunswick', 'Michigan', 'Connecticut',\n",
       "       'Alabama', 'Oklahoma', 'Oregon', 'Wyoming',\n",
       "       'Newfoundland and Labrador', 'Arizona', 'Colima', 'Tennessee',\n",
       "       'Virginia', 'Northwest Territories', 'South Carolina', 'Indiana',\n",
       "       'Maryland', 'Louisiana', 'Vermont', 'Queretaro De Arteaga',\n",
       "       'New Jersey', 'Kentucky', 'Arkansas', 'Nevada', 'Manitoba',\n",
       "       'Nova Scotia', 'Alaska', 'QLD', 'Idaho', 'Iowa', 'Quebec',\n",
       "       'New Hampshire', 'Kansas', 'U.S. Virgin Islands', 'Hawaii',\n",
       "       'Saskatchewan', 'Prince Edward Island', 'San Luis Potosi', 'OTAGO',\n",
       "       'South Dakota', 'Montana', 'UK', 'North Dakota', 'Mississippi',\n",
       "       'IE', 'DV', 'QUÃ‰BEC', 'Michoacan De Ocampo', 'EU', 'Yukon', 'CH',\n",
       "       'PY', 'Puerto Rico', 'British Columbia', 'KA', 'HESSE', 'NRW',\n",
       "       'DL', 'Tlaxcala', 'Maine', '', 'Veracruz Llave', 'C', 'SG', 'TL',\n",
       "       'SA', 'AU', 'A', 'NZ', 'Sinaloa', 'FR', 'BW', 'Nunavut',\n",
       "       'Campeche', 'MVD', 'SP', 'MX', 'Tamaulipas', 'Guam', 'OSLO', 'UY',\n",
       "       'QB', 'RAJASTHAN', 'RO', 'CLUJ', 'NG', 'RJ', 'HESSEN',\n",
       "       'Marshall Islands'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['State/Province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, states in enumerate(file['State/Province']):\n",
    "     for j in file2['code_state']:\n",
    "        if j.split(' ')[1] not in states:\n",
    "            file.loc[i,'State/Province']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e51a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(subset = ['State/Province'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efaad1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cae54e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42652,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['State/Province'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf81bba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pennsylvania', 'NAN', 'Texas', 'Minnesota', 'Illinois',\n",
       "       'Wisconsin', 'Florida', 'Rhode Island', 'Utah', 'New York',\n",
       "       'Ontario', 'Massachusetts', 'California', 'Delaware', 'New Mexico',\n",
       "       'Alberta', 'North Carolina', 'Washington', 'Missouri',\n",
       "       'West Virginia', 'District of Columbia', 'Nebraska', 'Colorado',\n",
       "       'Georgia', 'Ohio', 'New Brunswick', 'Michigan', 'Connecticut',\n",
       "       'Alabama', 'Oklahoma', 'Oregon', 'Wyoming',\n",
       "       'Newfoundland and Labrador', 'Arizona', 'Colima', 'Tennessee',\n",
       "       'Virginia', 'Northwest Territories', 'South Carolina', 'Indiana',\n",
       "       'Maryland', 'Louisiana', 'Vermont', 'Queretaro De Arteaga',\n",
       "       'New Jersey', 'Kentucky', 'Arkansas', 'Nevada', 'Manitoba',\n",
       "       'Nova Scotia', 'Alaska', 'QLD', 'Idaho', 'Iowa', 'Quebec',\n",
       "       'New Hampshire', 'Kansas', 'U.S. Virgin Islands', 'Hawaii',\n",
       "       'Saskatchewan', 'Prince Edward Island', 'San Luis Potosi', 'OTAGO',\n",
       "       'South Dakota', 'Montana', 'UK', 'North Dakota', 'Mississippi',\n",
       "       'IE', 'DV', 'QUÃ‰BEC', 'Michoacan De Ocampo', 'EU', 'Yukon', 'CH',\n",
       "       'PY', 'Puerto Rico', 'British Columbia', 'KA', 'HESSE', 'NRW',\n",
       "       'DL', 'Tlaxcala', 'Maine', '', 'Veracruz Llave', 'C', 'SG', 'TL',\n",
       "       'SA', 'AU', 'A', 'NZ', 'Sinaloa', 'FR', 'BW', 'Nunavut',\n",
       "       'Campeche', 'MVD', 'SP', 'MX', 'Tamaulipas', 'Guam', 'OSLO', 'UY',\n",
       "       'QB', 'RAJASTHAN', 'RO', 'CLUJ', 'NG', 'RJ', 'HESSEN',\n",
       "       'Marshall Islands'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['State/Province'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54333cf2",
   "metadata": {},
   "source": [
    "# Extract main industry from industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0787aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.loc[file['Industry_edited']=='Accounting','Industry_edited']='Finance'\n",
    "file.loc[file['Industry_edited']=='Consulting','Industry_edited']='Finance'\n",
    "file.loc[file['Industry_edited']=='Banking','Industry_edited']='Finance'\n",
    "file.loc[file['Industry_edited']=='Business','Industry_edited']='Sale & Production'\n",
    "file.loc[file['Industry_edited']=='Commerce','Industry_edited']='Sale & Production'\n",
    "file.loc[file['Industry_edited']=='Sale & Retail','Industry_edited']='Sale & Production'\n",
    "file.loc[file['Industry_edited']=='Production Line','Industry_edited']='Sale & Production'\n",
    "file.loc[file['Industry_edited']=='Marketimg','Industry_edited']='Marketing'\n",
    "file.loc[file['Industry_edited']=='Advertising','Industry_edited']='Marketing'\n",
    "file.loc[file['Industry_edited']=='Film Industry','Industry_edited']='Entertainment'\n",
    "file.loc[file['Industry_edited']=='Filming','Industry_edited']='Entertainment'\n",
    "file.loc[file['Industry_edited']=='Healthcare','Industry_edited']='Medical'\n",
    "file.loc[file['Industry_edited']=='Health Care','Industry_edited']='Medical'\n",
    "file.loc[file['Industry_edited']=='Clinic','Industry_edited']='Medical'\n",
    "file.loc[file['Industry_edited']=='Nonprofit','Industry_edited']='Non Profit'\n",
    "file.loc[file['Industry_edited']=='Building','Industry_edited']='Architecture'\n",
    "file.loc[file['Industry_edited']=='Biotech','Industry_edited']='Tech Company'\n",
    "file.loc[file['Industry_edited']=='Insurance','Industry_edited']='Customer Service'\n",
    "file.loc[file['Industry_edited']=='Beverage','Industry_edited']='Food'\n",
    "file.loc[file['Industry_edited']=='food','Industry_edited']='Food'\n",
    "file.loc[file['Industry_edited']=='Agriculture','Industry_edited']='Food'\n",
    "file.loc[file['Industry_edited']=='E-commerce','Industry_edited']='IT'\n",
    "file.loc[file['Industry_edited']=='Vehicle','Industry_edited']='Transportation'\n",
    "file.loc[file['Industry_edited']=='Automotive','Industry_edited']='Transportation'\n",
    "file.loc[file['Industry_edited']=='Beauty','Industry_edited']='Fashion & Clothes'\n",
    "file.loc[file['Industry_edited']=='Fashion ','Industry_edited']='Fashion & Clothes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c0c7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Medical', 'Tech Company', 'Marketing', 'Sale & Production',\n",
       "       'Government', 'HR', nan, 'Mortgage', 'Energy', 'Finance',\n",
       "       'Customer Service', 'Education', 'Transportation', 'IT', 'Food',\n",
       "       'Engineer', 'Architecture', 'Professional Degree', 'Entertainment',\n",
       "       'Real Estate', 'Fashion & Clothes', 'Communication', 'Non Profit',\n",
       "       'Arts', 'Filming ', 'Chemical', 'Animal', 'Casino',\n",
       "       'Administration', 'Aerospace'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Industry_edited'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50b80b",
   "metadata": {},
   "source": [
    "# Extract the annual total salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d374149",
   "metadata": {},
   "source": [
    "Calculating the annual total salary using base salary + bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8a7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file[-(file['Annual Salary'] == 'Professional Degree')]\n",
    "file.dropna(subset = ['Annual Salary'], inplace=True)\n",
    "file.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "478ba641",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Annual Salary']=file['Annual Salary'].replace('\\D','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88f3e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file[-(file['Annual Salary'] == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0fc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in file['Annual Salary']:\n",
    "     list.append(float(i))\n",
    "file['Annual Salary'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a63b1881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        85000\n",
       "1        97000\n",
       "2        57000\n",
       "3        80000\n",
       "4        95000\n",
       "         ...  \n",
       "41839    83000\n",
       "41840    55000\n",
       "41841    70000\n",
       "41842    95000\n",
       "41843    34000\n",
       "Name: Annual Salary, Length: 41839, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Annual Salary'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a352ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41839 entries, 0 to 41843\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Timestamp                     41839 non-null  object \n",
      " 1   Age Range                     41822 non-null  object \n",
      " 2   Years of Experience           41839 non-null  object \n",
      " 3   Industry                      41839 non-null  object \n",
      " 4   Industry_edited               31641 non-null  object \n",
      " 5   Job Title                     41453 non-null  object \n",
      " 6   Level of Education            41839 non-null  object \n",
      " 7   Major City                    41839 non-null  object \n",
      " 8   Country                       40663 non-null  object \n",
      " 9   Annual Salary                 41839 non-null  float64\n",
      " 10  Annual Bonus                  28818 non-null  object \n",
      " 11  Currency                      41839 non-null  object \n",
      " 12  Vacation per Year             39030 non-null  object \n",
      " 13  Sick Days per Year            33818 non-null  object \n",
      " 14  Maternity/Paternity per Year  24791 non-null  object \n",
      " 15  Gender                        41839 non-null  object \n",
      " 16  State/Province                41839 non-null  object \n",
      "dtypes: float64(1), object(16)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c8b4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Annual Bonus']=file['Annual Bonus'].replace('[a-zA-Z]','',regex=True)\n",
    "file['Annual Bonus']=file['Annual Bonus'].replace(' ','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe1b3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bns in enumerate(file['Annual Bonus']):\n",
    "    file.loc[i,'Annual Bonus']= str(bns).split('-')[0]\n",
    "       \n",
    "file['Annual Bonus']=file['Annual Bonus'].replace('\\D','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a37db26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.loc[file['Annual Bonus']=='','Annual Bonus'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd865d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(subset = ['Annual Salary'], inplace=True)\n",
    "file.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09c35124",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Annual Bonus']=file['Annual Bonus'].astype(float)\n",
    "file['Annual Salary']=file['Annual Salary'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "784c160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bns in enumerate(file['Annual Bonus']):\n",
    "    if bns > 0 and bns < 100:\n",
    "        file.loc[i,'Annual Salary']=file.loc[i,'Annual Salary']*(1+bns*0.01)\n",
    "    else:\n",
    "        file.loc[i,'Annual Salary']=file.loc[i,'Annual Salary'] + file.loc[i,'Annual Bonus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59e06e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41844 entries, 0 to 41592\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Timestamp                     41839 non-null  object \n",
      " 1   Age Range                     41822 non-null  object \n",
      " 2   Years of Experience           41839 non-null  object \n",
      " 3   Industry                      41839 non-null  object \n",
      " 4   Industry_edited               31641 non-null  object \n",
      " 5   Job Title                     41453 non-null  object \n",
      " 6   Level of Education            41839 non-null  object \n",
      " 7   Major City                    41839 non-null  object \n",
      " 8   Country                       40663 non-null  object \n",
      " 9   Annual Salary                 41837 non-null  float64\n",
      " 10  Annual Bonus                  41842 non-null  float64\n",
      " 11  Currency                      41839 non-null  object \n",
      " 12  Vacation per Year             39030 non-null  object \n",
      " 13  Sick Days per Year            33818 non-null  object \n",
      " 14  Maternity/Paternity per Year  24791 non-null  object \n",
      " 15  Gender                        41839 non-null  object \n",
      " 16  State/Province                41839 non-null  object \n",
      "dtypes: float64(2), object(15)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18d82ec",
   "metadata": {},
   "source": [
    "# extract currency type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbdab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(subset = ['Age Range','Industry','Level of Education','Years of Experience','Currency'], inplace=True)\n",
    "file.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90cc5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in file['Currency']:\n",
    "     list.append(str(i))\n",
    "file['Currency'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e29b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cus in enumerate(file['Currency']):\n",
    "    if 'ca' in cus.lower():\n",
    "        file.loc[i,'Currency']='CAD'\n",
    "    elif 'cad' in cus.lower():\n",
    "        file.loc[i,'Currency']='CAD'\n",
    "    elif 'us' in cus.lower():\n",
    "        file.loc[i,'Currency']='USD'\n",
    "    elif 'uds' in cus.lower():\n",
    "        file.loc[i,'Currency']='USD'\n",
    "    elif 'usd' in cus.lower():\n",
    "        file.loc[i,'Currency']='USD'\n",
    "    elif 'usa' in cus.lower():\n",
    "        file.loc[i,'Currency']='USD'\n",
    "    elif 'au' in cus.lower():\n",
    "        file.loc[i,'Currency']='AUD'\n",
    "    elif 'pound' in cus.lower():\n",
    "        file.loc[i,'Currency']='GBP'\n",
    "    elif 'gb' in cus.lower():\n",
    "        file.loc[i,'Currency']='GBP'\n",
    "    elif 'eu' in cus.lower():\n",
    "        file.loc[i,'Currency']='EUR'\n",
    "    elif 'nzd' in cus.lower():\n",
    "        file.loc[i,'Currency']='NZD'\n",
    "    elif 'newzea' in cus.lower():\n",
    "        file.loc[i,'Currency']='NZD'\n",
    "    elif 'isd' in cus.lower():\n",
    "        file.loc[i,'Currency']='ISD'\n",
    "    elif 'mxn' in cus.lower():\n",
    "        file.loc[i,'Currency']='MXN'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db3da882",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cus in enumerate(file['Currency']):\n",
    "    if len(cus) != 3:\n",
    "        file.loc[i,'Currency'] = np.nan\n",
    "    elif 'N/a' in cus:\n",
    "        file.loc[i,'Currency'] = np.nan\n",
    "    else:\n",
    "        file.loc[i,'Currency']=file.loc[i,'Currency'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ed4d6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USD', 'CAD', 'AUD', 'Ysd', 'ISD', 'UDD', 'UFD', 'NZD', 'GBP',\n",
       "       'EUR', 'UDF', 'UAD', 'CHF', 'ASD', 'GDP', 'YSD', 'MXN', 'ðŸ‡ºðŸ‡¸ ',\n",
       "       'PHP', 'SGD', 'MYR', 'ISS', 'AID'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Currency'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29582a2",
   "metadata": {},
   "source": [
    "# Change year of experience dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5cbeeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Years of Experience']=file['Years of Experience'].replace('\\D','',regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b578b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Years of Experience']=file['Years of Experience'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6ecd4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  1.,  2.,  4.,  5.,  8., 10.,  3.,  9., 17., 12.,  7., 11.,\n",
       "       16., 20., 15., 13., 14., 18., 19., nan])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Years of Experience'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65b3b2",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "035f0027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male', 'Non-binary', 'non-binary', 'non-binary ',\n",
       "       'Prefer Not to Say', 'Gender fluid', 'Non-binary ', 'Non-Binary',\n",
       "       'NB', 'Nonbinary/transmasc', 'Nonbinary', 'Non binary ',\n",
       "       'Female (selection above not working) ', 'Female/nonbinary',\n",
       "       'Gay male but fairly them-y', 'Non binary', 'Genderqueer ',\n",
       "       'non binary ', 'Non-binary/queergender',\n",
       "       'Genderqueer, Transmasculine', 'Trans man', 'Genderfluid ',\n",
       "       'Trans Female', 'Male/Non-binary', 'nonbinary', 'Non-conforming',\n",
       "       'Genderqueer', 'Trans man ', 'bigender, transgender',\n",
       "       'Non-binary femme', nan], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cc2a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, gen in enumerate(file['Gender']):\n",
    "    if 'female' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Female'\n",
    "    elif 'non' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Non-Binary'\n",
    "    elif 'nb' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Non-Binary'\n",
    "    elif 'fluid' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Non-Binary'\n",
    "    elif 'queer' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Non-Binary'\n",
    "    elif 'bi' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Non-Binary'\n",
    "    elif 'male' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Male'\n",
    "    elif 'trans' in gen.lower():\n",
    "        file.loc[i,'Gender'] = 'Transgender'\n",
    "    elif 'prefer' in gen.lower():\n",
    "        file.loc[i,'Gender'] = np.nan\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe7e12d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male', 'Non-Binary', nan, 'Transgender'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37e4640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.dropna(subset = ['Gender'], inplace = True)\n",
    "file.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7324b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file['Years of Experience'] = file['Years of Experience'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1d882bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41567 entries, 0 to 41566\n",
      "Data columns (total 17 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Timestamp                     41567 non-null  object \n",
      " 1   Age Range                     41567 non-null  object \n",
      " 2   Years of Experience           41567 non-null  int32  \n",
      " 3   Industry                      41567 non-null  object \n",
      " 4   Industry_edited               31432 non-null  object \n",
      " 5   Job Title                     41183 non-null  object \n",
      " 6   Level of Education            41567 non-null  object \n",
      " 7   Major City                    41567 non-null  object \n",
      " 8   Country                       40397 non-null  object \n",
      " 9   Annual Salary                 41567 non-null  float64\n",
      " 10  Annual Bonus                  41567 non-null  float64\n",
      " 11  Currency                      41567 non-null  object \n",
      " 12  Vacation per Year             38781 non-null  object \n",
      " 13  Sick Days per Year            33602 non-null  object \n",
      " 14  Maternity/Paternity per Year  24625 non-null  object \n",
      " 15  Gender                        41567 non-null  object \n",
      " 16  State/Province                41567 non-null  object \n",
      "dtypes: float64(2), int32(1), object(14)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1edaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
